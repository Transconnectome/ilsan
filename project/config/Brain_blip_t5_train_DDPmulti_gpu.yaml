wandb:
    API_KEY: 

dataset:
    img_dir: 
    meta_dir: 
    add_context: True
    train_size: 0.8
    val_size: 0.1
    test_size: 0.1
    img_size: 128
model: 
    architecture: "blip2_t5"
    type: "pretrain_flant5xl"
    image_encoder:
        freeze_vit: True
        lora_vit: False
    language_encoder: 
        lora_llm: False
        max_txt_len: 32

training_parameters:
    seed: 1234
    batch_size: 2
    accumulation_steps: 16
    optimizer: "AdamW"
    learning_rate: 0.0001
    weight_decay: 0.01
    lr_scheduler: 

pl_trainer: 
    max_epochs: 100
    devices: 'auto' 
    accelerator: 'gpu'
    precision: 16
    num_nodes: 1
    strategy: 'DDP'
    logger: "wandb" 
    log_every_n_steps: 1
    ckpt_dir: "/your/own/path/for/ckpt/file"
    resume_training: False
