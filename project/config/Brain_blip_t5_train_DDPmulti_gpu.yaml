wandb:
    API_KEY: "d3aa43e2c12e48489b08c4a1ee19de1ff8f88e0f"

dataset:
    img_dir: "/pscratch/sd/h/heehaw/ilsan/sample_img"
    meta_dir: "/pscratch/sd/h/heehaw/ilsan/meta_data.xlsx"
    add_context: True
    train_size: 0.8
    val_size: 0.1
    test_size: 0.1
    img_size: 128
model: 
    architecture: "blip2_t5"
    type: "pretrain_flant5xl"
    image_encoder:
        freeze_vit: True
        lora_vit: False
    language_encoder: 
        lora_llm: False
        max_txt_len: 32

training_parameters:
    seed: 1234
    batch_size: 2
    accumulation_steps: 16
    optimizer: "AdamW"
    learning_rate: 0.0001
    weight_decay: 0.01
    lr_scheduler: 

pl_trainer: 
    max_epochs: 100
    devices: 'auto' 
    accelerator: 'gpu'
    precision: 16
    num_nodes: 1
    strategy: 'DDP'
    logger: "wandb" 
    log_every_n_steps: 1
    ckpt_dir: "/pscratch/sd/h/heehaw/ilsan/project/output/checkpoint"
    resume_training: False
