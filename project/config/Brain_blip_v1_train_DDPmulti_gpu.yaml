wandb:
    API_KEY: 

dataset:
    img_dir: 
    meta_dir: 
    add_context: True
    train_size: 0.8
    val_size: 0.1
    test_size: 0.1
model: 
    image_encoder:
        vit_model: "eva_clip_g"
        img_size: 128
        patch_size: 16
        drop_path_rate: 0
        use_grad_checkpoint: False
        freeze_vit: True
        lora_vit: False
        num_query_token: 32
    language_encoder: 
        lm_model: "Qwen/Qwen-7B-Chat"
        prompt: ""
        max_txt_len: 100
        apply_lemmatizer: False
        embed_dim: 256
        use_flash_attn: False

training_parameters:
    seed: 1234
    batch_size: 2
    accumulation_steps: 16
    optimizer: "AdamW"
    learning_rate: 0.0001
    weight_decay: 0.01
    lr_scheduler: 

pl_trainer: 
    max_epochs: 100
    devices: 'auto' 
    accelerator: 'gpu'
    precision: 'bf16'
    num_nodes: 1
    strategy: 'DDP'
    logger: "wandb" 
    log_every_n_steps: 1
